# Global .env template for COMPOSE-CHECKPOINTS
# Uncomment the section for your machine config below.
# Only uncomment one section at a time.
# Then copy this file to .env and run docker-compose.

# --- Turing 1GPU 16GB VRAM 64GB RAM ---
# GPU_COUNT=1
# TOTAL_VRAM_GB=16
# GPU_MEM_UTIL=0.9
# BACKEND_CONTAINERS=vllm-model-a,vllm-model-b
# VLLM_VERSION=v0.10.2
# MAX_REQUESTS_PER_WINDOW=8
# MAX_WINDOW_DURATION_MS=500
# IDLE_SLEEP_MS=20
# MODEL_A=joshmiller656/Llama3.2-3B-Instruct-AWQ-INT4
# MODEL_NAME_A=llama3.2-3b
# MODEL_B=Qwen/Qwen3-4B-AWQ
# MODEL_NAME_B=qwen3-4b-awq

# --- Ampere 1GPU 12GB VRAM 64GB RAM ---
# GPU_COUNT=1
# TOTAL_VRAM_GB=12
# GPU_MEM_UTIL=0.85
# BACKEND_CONTAINERS=vllm-model-a,vllm-model-b
# VLLM_VERSION=v0.11.0
# MAX_REQUESTS_PER_WINDOW=6
# MAX_WINDOW_DURATION_MS=500
# IDLE_SLEEP_MS=20
# MODEL_A=joshmiller656/Llama3.2-3B-Instruct-AWQ-INT4
# MODEL_NAME_A=llama3.2-3b
# MODEL_B=RichardErkhov/ibm-granite_-_granite-3b-code-base-128k-awq
# MODEL_NAME_B=granite-3b-code

# --- Ampere 2GPU 24GB VRAM 128GB RAM ---
# GPU_COUNT=2
# TOTAL_VRAM_GB=24
# GPU_MEM_UTIL=0.95
# BACKEND_CONTAINERS=vllm-model-a,vllm-model-b
# VLLM_VERSION=v0.11.0
# MAX_REQUESTS_PER_WINDOW=8
# MAX_WINDOW_DURATION_MS=500
# IDLE_SLEEP_MS=20
# MODEL_A=joshmiller656/Llama3.2-3B-Instruct-AWQ-INT4
# MODEL_NAME_A=llama3.2-3b
# MODEL_B=RichardErkhov/ibm-granite_-_granite-3b-code-base-128k-awq
# MODEL_NAME_B=granite-3b-code